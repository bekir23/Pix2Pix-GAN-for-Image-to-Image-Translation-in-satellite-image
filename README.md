# Pix2Pix-GAN-for-Image-to-Image-Translation-in-satellite-image

The Pix2Pix GAN is a general approach for image-to-image translation.
It is based on the conditional generative adversarial network, where a target image is generated, conditional on a given input image.

dataset that used for this project  comprised of satellite images of New York and their corresponding Google maps pages. 
The image translation problem involves converting satellite photos to Google maps format, or the reverse, Google maps images to Satellite photos.

The dataset is provided on the pix2pix website and can be downloaded as a 255-megabyte zip file.

https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/
![alt text](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/05/Plot-of-Google-Map-to-Satellite-Translated-Images-Using-Pix2Pix-After-10-Training-Epochs.png)
